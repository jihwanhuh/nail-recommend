{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86ed8cd-9314-404a-bbea-38def7c7472d",
   "metadata": {},
   "source": "# 네이버 검색 + 블로그 본문 스크랩"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 정보 입력 / 전역 설정",
   "id": "890d041ab151b0d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 환경 변수",
   "id": "878b639006b6b8e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:22:45.943471Z",
     "start_time": "2025-11-19T18:22:45.898984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 실행 순번 - 경로에 사용\n",
    "RUN_INDEX = 1                 # 실행한 번호 - 수동 수정\n",
    "\n",
    "# --- 검색 일자 ---\n",
    "start_date = '20250101'\n",
    "end_date = ''                 # 입력 안 하면 오늘 날짜로 세팅\n",
    "\n",
    "# --- 스크롤 횟수 ---\n",
    "scroll_times = 10              # 스크롤 횟수\n",
    "\n",
    "# --- 다운로드 옵션 ---\n",
    "IS_SAVE_CSV = True            # CSV(엑셀용) 저장 여부\n",
    "IS_SAVE_IMAGES = False         # 이미지 저장 여부\n",
    "\n",
    "# --- 파일 다운로드 경로 (ROOT) --\n",
    "ROOT_DOWNLOAD_DIR = 'craw-download-file'"
   ],
   "id": "8f0e599dceeb3be3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 검색 키워드 입력",
   "id": "1584d822e00e8eb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:22:46.027041Z",
     "start_time": "2025-11-19T18:22:46.020147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 단일 키워드\n",
    "keyword = '네일추천'            # 검색 키워드\n",
    "search_keyword = keyword      # 검색창에 넣을 실제 값\n",
    "\n",
    "# 다중 키워드 (여러번 검색 수행) - 비어 있다면, 단일 키워드로 수행\n",
    "search_keywords = [\n",
    "    # 1) 기본/일반 네일 (베이스 분포용)\n",
    "    \"네일 추천\",\n",
    "    \"네일 디자인\",\n",
    "    \"셀프네일 디자인\",\n",
    "    \"데일리 네일\",\n",
    "    \"직장인 네일\",\n",
    "\n",
    "    # # 2) 쉐입 중심\n",
    "    # \"라운드 네일 디자인\",\n",
    "    # \"오벌 네일 디자인\",\n",
    "    # \"스퀘어 네일 디자인\",\n",
    "    # \"스퀘어오벌 네일\",\n",
    "    # \"아몬드 네일 디자인\",\n",
    "\n",
    "    # # 3) 길이·손 특징 중심\n",
    "    # \"짧은 손톱 네일\",\n",
    "    # \"짧은손톱 셀프네일\",\n",
    "    # \"긴 손톱 네일\",\n",
    "    # \"손가락 길어보이는 네일\",\n",
    "    # \"손이 예뻐보이는 네일\",\n",
    "]"
   ],
   "id": "7368b46bac9fd759",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 함수 정의",
   "id": "152586391929047d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 모듈 import",
   "id": "63449e9b18bda4d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:22:50.949642Z",
     "start_time": "2025-11-19T18:22:46.047580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import mimetypes"
   ],
   "id": "ddb3a8e11782db46",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 파일 경로",
   "id": "cc05292b665c322c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:22:51.967639Z",
     "start_time": "2025-11-19T18:22:51.954708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## 파일 경로 : 일자 + 실행 순번 + 검색어 or multi\n",
    "\n",
    "today_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "def sanitize_keyword(kw: str) -> str:\n",
    "    \"\"\"파일/폴더명으로 쓸 수 있게 키워드 정제 \"\"\"\n",
    "    if not isinstance(kw, str):\n",
    "        kw = str(kw)\n",
    "    kw = kw.strip().strip('\"').strip(\"'\")\n",
    "    # 파일명에 쓸 수 없는 문자 제거\n",
    "    kw = re.sub(r'[\\\\/:*?\"<>|]', '_', kw)\n",
    "    # 너무 길면 잘라내기\n",
    "    if len(kw) == 0:\n",
    "        kw = \"keyword\"\n",
    "    return kw\n",
    "\n",
    "### 단일/다중에 따라 파일명 기준 키워드 결정\n",
    "if search_keywords:          # 다중 키워드 리스트가 비어있지 않다면\n",
    "    base_keyword_for_path = \"multi\"\n",
    "else:\n",
    "    base_keyword_for_path = search_keyword\n",
    "\n",
    "SAFE_KEYWORD = sanitize_keyword(base_keyword_for_path)\n",
    "\n",
    "SUB_NAME = f\"{today_date}_{RUN_INDEX:02d}_{SAFE_KEYWORD}\"\n",
    "\n",
    "CSV_PATH = os.path.join(ROOT_DOWNLOAD_DIR, f\"{SUB_NAME}.csv\")\n",
    "IMAGE_DIR = os.path.join(ROOT_DOWNLOAD_DIR, SUB_NAME)"
   ],
   "id": "6b74f4520a26a7e3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 날짜 정규화",
   "id": "4df99b20bd26b29e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:22:52.017628Z",
     "start_time": "2025-11-19T18:22:51.987660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "KST = timezone(timedelta(hours=9))\n",
    "\n",
    "_abs = re.compile(r\"^\\s*(\\d{4})\\.(\\d{1,2})\\.(\\d{1,2})\\.?\\s*$\")\n",
    "_m  = re.compile(r\"(\\d+)\\s*분\\s*전\")\n",
    "_h  = re.compile(r\"(\\d+)\\s*시간\\s*전\")\n",
    "_d  = re.compile(r\"(\\d+)\\s*일\\s*전\")\n",
    "_w  = re.compile(r\"(\\d+)\\s*주\\s*전\")\n",
    "_not_date_tail = re.compile(r\"(?:단|TOP),\\s*$\")        # 예: \"A34면 1단,\" , \"A30면 TOP,\"\n",
    "\n",
    "def _ymd(dt: datetime) -> str:\n",
    "    # Python/Excel 공통 인식 포맷: YYYY-MM-DD\n",
    "    return f\"{dt.year:04d}-{dt.month:02d}-{dt.day:02d}\"\n",
    "\n",
    "def normalize_news_date(texts, now: datetime | None = None) -> str | None:\n",
    "    # 변환 실패 대비: 원본 첫 값 보관\n",
    "    original_first = texts if isinstance(texts, str) else (texts[0] if texts else None)\n",
    "\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    now = now or datetime.now(KST)\n",
    "\n",
    "    for t in texts:\n",
    "        if not t:\n",
    "            continue\n",
    "        s = t.strip()\n",
    "\n",
    "        # 지면/면·단, TOP 꼬리면 스킵\n",
    "        if _not_date_tail.search(s):\n",
    "            continue\n",
    "\n",
    "        # 절대형\n",
    "        m = _abs.match(s)\n",
    "        if m:\n",
    "            y, mo, d = map(int, m.groups())\n",
    "            return f\"{y:04d}-{mo:02d}-{d:02d}\"\n",
    "\n",
    "        # 상대형\n",
    "        if (mm := _h.search(s)): # 분\n",
    "            return _ymd(now - timedelta(minutes=int(mm.group(1))))\n",
    "        if (mh := _h.search(s)): # 시간\n",
    "            return _ymd(now - timedelta(hours=int(mh.group(1))))\n",
    "        if (md := _d.search(s)): # 일\n",
    "            return _ymd(now - timedelta(days=int(md.group(1))))\n",
    "        if (mw := _w.search(s)): # 주\n",
    "            return _ymd(now - timedelta(weeks=int(mw.group(1))))\n",
    "\n",
    "    # 날짜형 변환이 안되면 첫 번째 값 반환\n",
    "    return original_first"
   ],
   "id": "39973217f779552f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 검색 결과 카드 한 개에서 정보 추출",
   "id": "2465021e4aaaeec8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:22:52.053373Z",
     "start_time": "2025-11-19T18:22:52.031434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_content(review):\n",
    "    condic = {}\n",
    "\n",
    "    title_css  = (\n",
    "        \"span.sds-comps-text.sds-comps-text-ellipsis.sds-comps-text-ellipsis-1\"\n",
    "        \".sds-comps-text-type-headline1.sds-comps-text-weight-sm\"\n",
    "    )\n",
    "    text_css   = (\n",
    "        \"span.sds-comps-text-type-body1\"\n",
    "    )\n",
    "    viewer_css = (\n",
    "        \"div.sds-comps-horizontal-layout.sds-comps-inline-layout\"\n",
    "        \".sds-comps-profile-info-title\"\n",
    "    )\n",
    "    date_css   = (\n",
    "        \"span.sds-comps-text.sds-comps-text-type-body2\"\n",
    "        \".sds-comps-text-weight-sm.sds-comps-profile-info-subtext\"\n",
    "    )\n",
    "    link_css   = 'a[href*=\"blog.naver.com\"]'\n",
    "\n",
    "    condic['writer'] = review.find_element(By.CSS_SELECTOR, viewer_css) \\\n",
    "                             .get_attribute('innerText').strip()\n",
    "    condic['title'] = review.find_element(By.CSS_SELECTOR, title_css) \\\n",
    "                             .get_attribute('innerText').strip()\n",
    "    condic['text'] = review.find_element(By.CSS_SELECTOR, text_css) \\\n",
    "                            .get_attribute('innerText').strip()\n",
    "    condic['date'] = normalize_news_date(\n",
    "        review.find_element(By.CSS_SELECTOR, date_css)\n",
    "              .get_attribute('innerText').strip()\n",
    "    )\n",
    "    try:\n",
    "        condic['link'] = review.find_element(By.CSS_SELECTOR, link_css) \\\n",
    "                                .get_attribute('href')\n",
    "    except Exception:\n",
    "        condic['link'] = ''\n",
    "        print(f\"condic['link'] -> 추출오류 : {condic['title']}\")\n",
    "\n",
    "    return condic"
   ],
   "id": "50ced03c97c32265",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 블로그 본문 크롤링 + 이미지 저장",
   "id": "eb16d4e87c7d718a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:22:52.111040Z",
     "start_time": "2025-11-19T18:22:52.070704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def crawl_blog_content(url: str, search_idx: int,\n",
    "                       image_dir: str,\n",
    "                       is_download_images: bool = True):\n",
    "\n",
    "    COMMON_HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    resp = requests.get(url, headers=COMMON_HEADERS)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    # iframe 찾기\n",
    "    iframe = soup.select_one(\"iframe#mainFrame\")\n",
    "    if iframe is None:\n",
    "        for f in soup.find_all(\"iframe\"):\n",
    "            src = f.get(\"src\") or \"\"\n",
    "            if \"PostView\" in src:\n",
    "                iframe = f\n",
    "                break\n",
    "\n",
    "    if iframe is None:\n",
    "        print(f\"[WARN] iframe 없음 → {url}\")\n",
    "        return {\"title\": \"\", \"full_text\": \"\", \"image_count\": 0}\n",
    "\n",
    "    inner_src = iframe.get(\"src\")\n",
    "    inner_url = urljoin(resp.url, inner_src)\n",
    "\n",
    "    # iframe 안쪽 요청\n",
    "    resp2 = requests.get(inner_url, headers=COMMON_HEADERS)\n",
    "    resp2.raise_for_status()\n",
    "    soup2 = BeautifulSoup(resp2.text, \"html.parser\")\n",
    "\n",
    "    # 제목\n",
    "    title_tag = soup2.find(\"title\")\n",
    "    title = title_tag.get_text(strip=True) if title_tag else \"\"\n",
    "\n",
    "    # 본문 텍스트\n",
    "    paragraphs = [p.get_text(\" \", strip=True) for p in soup2.find_all(\"p\")]\n",
    "    full_text = \"\\n\".join(paragraphs)\n",
    "\n",
    "    if not full_text.strip():\n",
    "        main_div = soup2.select_one(\"div.se-main-container\")\n",
    "        if main_div:\n",
    "            paragraphs = [\n",
    "                p.get_text(\" \", strip=True)\n",
    "                for p in main_div.find_all([\"p\", \"span\"])\n",
    "            ]\n",
    "            full_text = \"\\n\".join(paragraphs)\n",
    "\n",
    "    # 이미지 다운로드\n",
    "    image_count = 0\n",
    "    if is_download_images:\n",
    "        content = (\n",
    "            soup2.select_one(\"div.se-main-container\")\n",
    "            or soup2.select_one(\"#postViewArea\")\n",
    "            or soup2\n",
    "        )\n",
    "        img_tags = content.find_all(\"img\")\n",
    "\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "        allowed_hosts = (\"postfiles.pstatic.net\", \"blogfiles.pstatic.net\")\n",
    "\n",
    "        for img_idx, img in enumerate(img_tags, start=1):\n",
    "            src = img.get(\"data-origin\") or img.get(\"data-src\") or img.get(\"src\")\n",
    "            if not src:\n",
    "                continue\n",
    "\n",
    "            if not any(h in src for h in allowed_hosts):\n",
    "                continue\n",
    "\n",
    "            if src.startswith(\"//\"):\n",
    "                src = \"https:\" + src\n",
    "            elif src.startswith(\"/\"):\n",
    "                src = urljoin(inner_url, src)\n",
    "            if src.startswith(\"data:\"):\n",
    "                continue\n",
    "\n",
    "            hi_src = src\n",
    "            if \"type=w80_blur\" in src:\n",
    "                hi_src = src.replace(\"type=w80_blur\", \"type=w966\")\n",
    "\n",
    "            img_headers = {\n",
    "                \"User-Agent\": \"Mozilla/5.0\",\n",
    "                \"Referer\": inner_url,\n",
    "            }\n",
    "\n",
    "            img_resp = None\n",
    "            for candidate in [hi_src, src]:\n",
    "                try:\n",
    "                    r = requests.get(candidate, headers=img_headers, timeout=10)\n",
    "                    r.raise_for_status()\n",
    "                    img_resp = r\n",
    "                    break\n",
    "                except Exception:\n",
    "                    img_resp = None\n",
    "\n",
    "            if img_resp is None:\n",
    "                continue\n",
    "\n",
    "            content_type = img_resp.headers.get(\"Content-Type\", \"\")\n",
    "            if \"image\" not in content_type:\n",
    "                continue\n",
    "\n",
    "            if not is_download_images:\n",
    "                image_count += 1\n",
    "                continue\n",
    "\n",
    "            ext = mimetypes.guess_extension(content_type.split(\";\")[0]) or \".jpg\"\n",
    "\n",
    "            # IMG_{검색결과순번 4자리}_{본문내 이미지순번 4자리}\n",
    "            filename = os.path.join(\n",
    "                image_dir,\n",
    "                f\"IMG_{search_idx:04d}_{img_idx:04d}{ext}\"\n",
    "            )\n",
    "\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(img_resp.content)\n",
    "\n",
    "            image_count += 1\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"full_text\": full_text,\n",
    "        \"image_count\": image_count,\n",
    "    }\n",
    "\n",
    "\n",
    "def enrich_with_blog_contents(df_search: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1번 검색 df 기준:\n",
    "    - title 덮어쓰기 (블로그 실제 제목)\n",
    "    - full_text 열 추가\n",
    "    - image_count 열 추가\n",
    "    \"\"\"\n",
    "\n",
    "    df = df_search.copy()\n",
    "    df[\"full_text\"] = \"\"\n",
    "    df[\"image_count\"] = 0\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        url = row.get(\"link\", \"\")\n",
    "        if not isinstance(url, str) or not url.strip():\n",
    "            continue\n",
    "\n",
    "        search_idx = idx + 1\n",
    "        print(f\"[{search_idx}/{len(df)}] {url}\")\n",
    "\n",
    "        info = crawl_blog_content(\n",
    "            url=url,\n",
    "            search_idx=search_idx,\n",
    "            image_dir=IMAGE_DIR,\n",
    "            is_download_images=IS_SAVE_IMAGES\n",
    "        )\n",
    "\n",
    "        df.at[idx, \"title\"] = info[\"title\"]\n",
    "        df.at[idx, \"full_text\"] = info[\"full_text\"]\n",
    "        df.at[idx, \"image_count\"] = info[\"image_count\"]\n",
    "\n",
    "    return df"
   ],
   "id": "27d6964cdf546f01",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 실행부",
   "id": "d5cee742cf9dd0b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 검색 페이지 로드 / 스크롤 / 본문 스크랩",
   "id": "d851fde826038502"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:27:11.855052Z",
     "start_time": "2025-11-19T18:22:52.130462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "from time import sleep\n",
    "import random\n",
    "\n",
    "def encode_keyword(search_keyword: str) -> str:\n",
    "    return quote_plus(search_keyword)\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 다중 키워드가 있으면 그걸 사용, 없으면 단일 search_keyword 사용\n",
    "if search_keywords:\n",
    "    keywords_to_run = search_keywords\n",
    "else:\n",
    "    keywords_to_run = [search_keyword]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for q in keywords_to_run:\n",
    "    print(f\"\\n=== 검색 시작: {q} ===\")\n",
    "    enc_q = encode_keyword(q)\n",
    "\n",
    "    url = (\n",
    "        \"https://search.naver.com/search.naver\"\n",
    "        \"?ssc=tab.blog.all\"\n",
    "        \"&sm=tab_opt\"\n",
    "        \"&where=blog\"\n",
    "        f\"&query={enc_q}\"\n",
    "        f\"&nso=so%3Ar%2Cp%3Afrom{start_date}to{end_date}\"\n",
    "    )\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    # 스크롤\n",
    "    xp = '/html'\n",
    "    review_box = driver.find_element(By.XPATH, xp)\n",
    "\n",
    "    for _ in range(scroll_times):\n",
    "        driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', review_box)\n",
    "        sleep(random.randint(2, 3))\n",
    "\n",
    "    # 박스 선택\n",
    "    forms = driver.find_elements(\n",
    "        By.CSS_SELECTOR,\n",
    "        'div.sds-comps-vertical-layout.sds-comps-full-layout.YNThgbNOBFUb3Wc2Cq47'\n",
    "    )\n",
    "    print('박스 수 :', len(forms))\n",
    "\n",
    "    # 카드별 정보 수집\n",
    "    success = 0\n",
    "    # fail_stats = {}\n",
    "    for i, form in enumerate(forms, start=1):\n",
    "        try:\n",
    "            dic = get_content(form)\n",
    "            dic[\"search_keyword\"] = q   # 어떤 검색어에서 나온 결과인지 기록\n",
    "            all_results.append(dic)\n",
    "            success += 1\n",
    "        except Exception as e:\n",
    "            name = type(e).__name__\n",
    "            # fail_stats[name] = fail_stats.get(name, 0) + 1\n",
    "            # print(f\"[{q}] 카드 {i}/{len(forms)} skip → {name}: {e}\")\n",
    "\n",
    "    # print(f\"[{q}] 성공: {success} / {len(forms)}\")\n",
    "    # print(f\"[{q}] 실패 통계: {fail_stats}\")\n",
    "\n",
    "# 모든 결과를 하나의 DataFrame으로\n",
    "df_search = pd.DataFrame(all_results)\n",
    "print(\"총 수집 건수:\", len(df_search))\n",
    "\n",
    "\n",
    "df_search['idx'] = range(len(df_search))\n",
    "\n",
    "cols = (['idx', 'search_keyword']\n",
    "        + [c for c in df_search.columns if c not in ['idx', 'search_keyword']])\n",
    "df_search = df_search[cols]\n",
    "\n",
    "df_search.head()"
   ],
   "id": "dc73e7085a7ce722",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 검색 시작: 네일 추천 ===\n",
      "박스 수 : 126\n",
      "condic['link'] -> 추출오류 : 네일아트하러 서울에서 방문하는 손더네일\n",
      "\n",
      "=== 검색 시작: 네일 디자인 ===\n",
      "박스 수 : 94\n",
      "condic['link'] -> 추출오류 : 네일아트 자격증 필기 실기에 대해서\n",
      "\n",
      "=== 검색 시작: 셀프네일 디자인 ===\n",
      "박스 수 : 110\n",
      "\n",
      "=== 검색 시작: 데일리 네일 ===\n",
      "박스 수 : 128\n",
      "\n",
      "=== 검색 시작: 직장인 네일 ===\n",
      "박스 수 : 137\n",
      "총 수집 건수: 595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   idx search_keyword             writer                               title  \\\n",
       "0    0          네일 추천                 깜썰             베트남 다낭 마사지 추천 핑크스파 네일아트   \n",
       "1    1          네일 추천    쥔이로그 : 뷰티&패션&팝업    자석젤 다이소 네일팁 웨딩네일 추천, 간단하게 포인트 주기   \n",
       "2    2          네일 추천       ★ 빛나는 나의 길 ★           경성대 부경대네일 랑만뷰티살롱 쿠로미네일 추천   \n",
       "3    3          네일 추천  뉴라와 구름이의 먹방 라이프⭐️  범계 속눈썹 연장 잘하는 벨라네일 추천 (주차, 애견동반가능)   \n",
       "4    4          네일 추천              [생각중]          강남 선릉역네일 화려한네일 전문샵 도쿄네일 추천   \n",
       "\n",
       "                                                text        date  \\\n",
       "0  베트남 다낭 마사지 추천 핑크스파 네일아트 하잉, 여행블로거 깜썰입니다 :) 남편 ...  2025-10-10   \n",
       "1  \"자석젤 다이소 네일팁 웨딩네일 추천, 간단하게 포인트 주기\" 안녕하세요! 쥔이입니...  2025-08-17   \n",
       "2  [ 경성대 부경대네일 랑만뷰티살롱 ] 쿠로미네일 추천 쿠로미 좋아하는 사람들 다 모...  2025-11-06   \n",
       "3  안녕하세요 뉴릉이입니다~ 저는 이번에 새로운 연장 잘 하는 곳을 찾다가 범계 속눈썹...  2025-11-17   \n",
       "4  규모가 크고 인테리어도 멋지면서 편안하게 네일을 받을 수 있는 강남 선릉역네일 화려...  2025-10-30   \n",
       "\n",
       "                                             link  \n",
       "0  https://blog.naver.com/jeongwon84/224036100473  \n",
       "1                  https://blog.naver.com/486xhxh  \n",
       "2                  https://blog.naver.com/wonnabe  \n",
       "3                  https://blog.naver.com/our0511  \n",
       "4                  https://blog.naver.com/molly32  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>search_keyword</th>\n",
       "      <th>writer</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>네일 추천</td>\n",
       "      <td>깜썰</td>\n",
       "      <td>베트남 다낭 마사지 추천 핑크스파 네일아트</td>\n",
       "      <td>베트남 다낭 마사지 추천 핑크스파 네일아트 하잉, 여행블로거 깜썰입니다 :) 남편 ...</td>\n",
       "      <td>2025-10-10</td>\n",
       "      <td>https://blog.naver.com/jeongwon84/224036100473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>네일 추천</td>\n",
       "      <td>쥔이로그 : 뷰티&amp;패션&amp;팝업</td>\n",
       "      <td>자석젤 다이소 네일팁 웨딩네일 추천, 간단하게 포인트 주기</td>\n",
       "      <td>\"자석젤 다이소 네일팁 웨딩네일 추천, 간단하게 포인트 주기\" 안녕하세요! 쥔이입니...</td>\n",
       "      <td>2025-08-17</td>\n",
       "      <td>https://blog.naver.com/486xhxh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>네일 추천</td>\n",
       "      <td>★ 빛나는 나의 길 ★</td>\n",
       "      <td>경성대 부경대네일 랑만뷰티살롱 쿠로미네일 추천</td>\n",
       "      <td>[ 경성대 부경대네일 랑만뷰티살롱 ] 쿠로미네일 추천 쿠로미 좋아하는 사람들 다 모...</td>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>https://blog.naver.com/wonnabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>네일 추천</td>\n",
       "      <td>뉴라와 구름이의 먹방 라이프⭐️</td>\n",
       "      <td>범계 속눈썹 연장 잘하는 벨라네일 추천 (주차, 애견동반가능)</td>\n",
       "      <td>안녕하세요 뉴릉이입니다~ 저는 이번에 새로운 연장 잘 하는 곳을 찾다가 범계 속눈썹...</td>\n",
       "      <td>2025-11-17</td>\n",
       "      <td>https://blog.naver.com/our0511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>네일 추천</td>\n",
       "      <td>[생각중]</td>\n",
       "      <td>강남 선릉역네일 화려한네일 전문샵 도쿄네일 추천</td>\n",
       "      <td>규모가 크고 인테리어도 멋지면서 편안하게 네일을 받을 수 있는 강남 선릉역네일 화려...</td>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>https://blog.naver.com/molly32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 블로그 본문 + 이미지 수집",
   "id": "a74caa05eb6308b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:27:12.510099Z",
     "start_time": "2025-11-19T18:27:12.503802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### 블로그 본문 + 이미지 수집\n",
    "if IS_SAVE_IMAGES :   # 이미지 저장 안하더라도 본문 수집은 수행\n",
    "    df_enriched = enrich_with_blog_contents(df_search)\n",
    "else:\n",
    "    df_enriched = df_search.copy()"
   ],
   "id": "f297aed15f7a4de",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CSV 저장",
   "id": "2be66e3f95023f50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:27:12.809492Z",
     "start_time": "2025-11-19T18:27:12.774556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### CSV 저장\n",
    "if IS_SAVE_CSV:\n",
    "    os.makedirs(ROOT_DOWNLOAD_DIR, exist_ok=True)\n",
    "    df_enriched.to_csv(CSV_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"CSV 저장 완료:\", CSV_PATH)"
   ],
   "id": "ed19dd59bd0b152",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 저장 완료: craw-download-file\\20251120_03_multi.csv\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
